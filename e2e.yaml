
Below is a full “from scratch” rebuild + regenerate + deploy to a fresh kind cluster, including building images for controller, gateway, and agent, loading them into kind, deploying everything, and verifying e2e.

Setup (one-time)
- Ensure Go 1.22+, Docker, kubectl, kind installed.
- Export a cluster name for reuse: `export KIND_CLUSTER=apollo-dev`
- Make sure your working tree is clean (`git status`).

1) Fresh kind cluster
```bash
kind delete cluster --name $KIND_CLUSTER || true
kind create cluster --name $KIND_CLUSTER
```

2) Regenerate code + CRDs and rebuild binaries
```bash
make tools            # installs controller-gen
make generate         # deepcopy etc.
make manifests        # CRDs into config/crd/bases
make build            # builds controller, gateway, agent binaries
```

3) Create Dockerfiles (once) in repo root
```bash
cat > Dockerfile.controller <<'EOF'
FROM golang:1.22-alpine AS builder
WORKDIR /workspace
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags="-s -w" -o /manager ./controller

FROM gcr.io/distroless/static:nonroot
COPY --from=builder /manager /manager
USER 65532
ENTRYPOINT ["/manager"]
EOF

cat > Dockerfile.gateway <<'EOF'
FROM golang:1.22-alpine AS builder
WORKDIR /workspace
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags="-s -w" -o /gateway ./cmd/gateway

FROM gcr.io/distroless/static:nonroot
COPY --from=builder /gateway /gateway
USER 65532
ENTRYPOINT ["/gateway"]
EOF

cat > Dockerfile.agent <<'EOF'
FROM golang:1.22-alpine AS builder
WORKDIR /workspace
COPY . .
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -ldflags="-s -w" -o /agent ./agent

FROM gcr.io/distroless/static:nonroot
COPY --from=builder /agent /agent
USER 65532
ENTRYPOINT ["/agent"]
EOF
```

4) Build images
```bash
docker build -f Dockerfile.controller -t apollo-deviceprocess-controller:dev .
docker build -f Dockerfile.gateway     -t apollo-deviceprocess-gateway:dev .
docker build -f Dockerfile.agent       -t apollo-deviceprocess-agent:dev .
```

5) Load images into kind
```bash
kind load docker-image apollo-deviceprocess-controller:dev --name $KIND_CLUSTER
kind load docker-image apollo-deviceprocess-gateway:dev     --name $KIND_CLUSTER
kind load docker-image apollo-deviceprocess-agent:dev       --name $KIND_CLUSTER
```

6) Deploy CRDs, RBAC, controller
```bash
kubectl apply -k config/crd
kubectl apply -k config/rbac
kubectl apply -k config/manager
kubectl -n default set image deploy/apollo-deviceprocess-controller manager=apollo-deviceprocess-controller:dev
kubectl -n default rollout status deploy/apollo-deviceprocess-controller
```

7) Deploy gateway + service (in-cluster)
```bash
cat <<'EOF' | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: apollo-deviceprocess-gateway
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels: {app: apollo-deviceprocess-gateway}
  template:
    metadata:
      labels: {app: apollo-deviceprocess-gateway}
    spec:
      serviceAccountName: apollo-deviceprocess-gateway
      containers:
      - name: gateway
        image: apollo-deviceprocess-gateway:dev
        args:
        - --addr=:8080
        - --default-heartbeat-seconds=15
        - --stale-multiplier=3
        - --device-token=devtoken
        ports:
        - containerPort: 8080
          name: http
---
apiVersion: v1
kind: Service
metadata:
  name: apollo-deviceprocess-gateway
  namespace: default
spec:
  selector: {app: apollo-deviceprocess-gateway}
  ports:
  - name: http
    port: 8080
    targetPort: 8080
EOF
kubectl rollout status deploy/apollo-deviceprocess-gateway
```

8) Deploy an agent inside the cluster (matches sample deviceRef.name)
```bash
cat <<'EOF' | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: apollo-deviceprocess-agent
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels: {app: apollo-deviceprocess-agent}
  template:
    metadata:
      labels: {app: apollo-deviceprocess-agent}
    spec:
      containers:
      - name: agent
        image: apollo-deviceprocess-agent:dev
        env:
        - name: APOLLO_DEVICE_NAME
          value: compute-01             # must match sample DeviceProcess deviceRef.name
        - name: APOLLO_GATEWAY_URL
          value: http://apollo-deviceprocess-gateway.default.svc.cluster.local:8080
        - name: APOLLO_DEVICE_TOKEN
          value: devtoken
EOF
kubectl rollout status deploy/apollo-deviceprocess-agent
```

9) Apply sample DeviceProcess (regenerated)
```bash
kubectl apply -f config/samples/azure_v1alpha1_deviceprocess.yaml
```

10) Verify end-to-end
- Gateway up: `kubectl logs deploy/apollo-deviceprocess-gateway`
- Agent up: `kubectl logs deploy/apollo-deviceprocess-agent`
- Controller up: `kubectl logs deploy/apollo-deviceprocess-controller`
- Status on DeviceProcess:
```bash
kubectl get deviceprocess systemd-log-forwarder -o yaml | grep -A10 status
kubectl describe deviceprocess systemd-log-forwarder
```
Expect `AgentConnected=True`, `SpecObserved=True` with hash and timestamp, Phase Pending.

11) Stale test (optional)
- Scale agent to zero: `kubectl scale deploy/apollo-deviceprocess-agent --replicas=0`
- Wait ~45s (15s heartbeat * 3 stale multiplier)
- Re-check status/conditions/events for `AgentDisconnected`.

This sequence rebuilds code, regenerates CRDs, builds all images, loads them into kind, deploys controller + gateway + agent, applies the sample DeviceProcess, and validates end-to-end behavior. If you want different device names or namespaces, adjust the DeviceProcess sample and the agent env accordingly.


The controller is error-looping because the `NetworkSwitch.azure.com/v1alpha1` CRD is not installed. Add a stub CRD so the watch can start:

```bash
cat <<'EOF' | kubectl apply -f -
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: networkswitches.azure.com
spec:
  group: azure.com
  names:
    kind: NetworkSwitch
    listKind: NetworkSwitchList
    plural: networkswitches
    singular: networkswitch
  scope: Namespaced
  versions:
  - name: v1alpha1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        type: object
        properties:
          spec:
            type: object
          status:
            type: object
EOF
```

Then restart the controller (or let it pick up the CRD automatically). After this, the “no matches for kind NetworkSwitch” errors should stop.